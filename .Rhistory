aPaclist <- c("xts","zoo","plyr","MTS","xlsx","gdata","forecast","ggplot2","lubridate")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
# library(xts)
# library(zoo)
# library(plyr)
# library(MTS)
# library(xlsx)
# library(gdata)
# library(forecast)
# library(ggplot2)
# library(lubridate)
# Read Google Data
# Select the folder where to read from
sFold = "O:/DATOS_BBVAResearch/FENIX_SC001628/Modelos/Turismo-Google/Flash"
vGuard <- 1
mData <- read.csv(paste(sFold,"/original.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding="latin1")
mData <- xts(mData[,-1], order.by=as.Date(mData$date))
mData0 <- read.csv(paste(sFold,"/datos_brutos/data-00000-of-00001.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding = "latin1")
mData0$CCAA <- gsub("Ã³","ó",mData0$CCAA)
mData0 <- xts(mData0[,-1], order.by=as.Date(mData0$date))
# Define name vectors
vCountry = c("AT", "CH", "DE","FR","IE","IT","UK","US","ES")
vCCAAabv <- c("ESP","AND","ARA","AST","BAL","CAN","CNT","CYL","CLM","CAT","VAL","EXT","GAL",
"MAD","MUR","NAV","PV","RIO")
vCCAA <- c("Spain","Andalusia","Aragon","Asturias","Balearic Islands","Canary Islands",
"Cantabria","Castille and León","Castile La Mancha","Catalonia","Valencian Community",
"Extremadura","Galicia","Community of Madrid","Region of Murcia","Navarre","Basque Country",
"La Rioja")
iC = length(vCountry)
# iP = length(vProd)
iCCAA <- length(vCCAA)
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData[mData$CCAA==vCCAA[m] &  mData$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData = do.call(merge, objList)    # merge all objects in list
# new data
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData0[mData0$CCAA==vCCAA[m] &  mData0$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var_new', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var_new*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData0 = do.call(merge, objList)    # merge all objects in list
# Delete variable which are not used
rm(list=
Filter(
Negate(is.na),                                  # filter entries corresponding to objects that don't meet function criteria
sapply(
ls(pattern="var*"),                             # only objects that start with "var"
function(x) if(is.matrix(get(x))) x else NA   # return names of matrix objects
)
)
)
mDf.tot <- mData
mDf.tot0 <- mData0
col <- which(!(colnames(mDf.tot) %in% colnames(mDf.tot0)))
colnames(mDf.tot)[col]
mDf.tot = mDf.tot["2007-07-01/2015-12-31"]
mDf.tot0 = mDf.tot0["2016-01-01/"]
mData_vf = rbind(mDf.tot, mDf.tot0)
#remove outliers
fun <- function(x){
quantiles <- quantile( x, c(.05, .97 ) )
x[ x < quantiles[1] ] <- quantiles[1]
x[ x > quantiles[2] ] <- quantiles[2]
x
}
mData_vf <- lapply(mData_vf,fun)
mData_vf <- as.data.frame(mData_vf)
mData_vf <- xts(mData_vf,order.by = as.Date(rownames(mData_vf)))
#create monthly and two week form raw data
mMonthly_raw = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week_raw = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week_raw = apply.monthly(mData_vf_two_week_raw, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales/Datos_brutos"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleWeekly_raw')
write.xlsx(mMonthly_raw, paste(sFold,Regionales,"/GoogleMonthly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_raw')
write.xlsx(mMonthly_two_week_raw,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks_raw')
}
# Indexing all series (equal 100 in the first week of data)
for (i in 1:ncol(mData_vf)){
iNonNA <- which(!is.na(mData_vf[,c(i)]))
iNonNAfst <- min(iNonNA) #encuentra el primer valor que no es NA y guarda su localizacióndim
dA = coredata(mData_vf[iNonNAfst,c(i)])
mData_vf[,c(i)] = drop(mData_vf[,c(i)])/dA*100 #divide todos entre ese valor *100
}
mMonthly = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week = apply.monthly(mData_vf_two_week, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg.xlsx",sep = ''), sheetName = 'GoogleWeekly')
write.xlsx(mMonthly, paste(sFold,Regionales,"/GoogleMonthly_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly')
write.xlsx(mMonthly_two_week,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks')
}
install.packages("eurostat")
library(eurostat)
get_eurostat_toc()
get_eurostat_toc()
toc <- get_eurostat_toc()
View(toc)
library(knitr)
install.packages("knitr"
)
library(knitr)
?kable
kable(head(toc))
head(toc)
as.data.frame(head(toc))
as.data.frame(head(search_eurostat("passenger transport")))
as.data.frame(head(search_eurostat("passenger transport")))
as.data.frame(head(search_eurostat("city")))
dfPrueba <- get_eurostat("env_wwcap_rb")
head(dfPrueba)
dfPrueba <- get_eurostat("tran_hv_pstra")
head(dfPrueba)
View(dfPrueba)
View(dfPRueba[order(dfPrueba[,2])])
View(dfPrueba[order(dfPrueba[,2])])
View(dfPrueba[order(dfPrueba$geo)])
View(dfPrueba[order(dfPrueba$geo),])
id <- search_eurostat("Modal slplit of passenger transport")
id <- search_eurostat("Modal split of passenger transport")
View(id)
View(id)
id <- search_eurostat("Modal split of passenger transport")$code[1]
id <- search_eurostat("Modal split of passenger transport",type="table")$code[1]
id <- search_eurostat("Modal split of passenger transport")
View(id)
id <- search_eurostat("Modal split of passenger transport",type="table")
id <- search_eurostat("Modal split of passenger transport")
id <- search_eurostat("Modal split of passenger transport")
id <- search_eurostat("Modal split of passenger transport")$code[1]
id2 <- search_eurostat("Modal split of passenger transport",type="table")$code[1]
dfPrueba <- get_eurostat(id)
dfPrueba2 <- get_eurostat(id2)
View(dfPrueba)
View(dfPrueba2)
shiny::runApp('C:/Users/e050752/Desktop/BBall')
runApp('C:/Users/e050752/Desktop/BBall')
runApp('C:/Users/e050752/Desktop/BBall')
impiar <- function(df.tot) {
df.tot$Rk <- NULL
df.tot$X <- NULL
df.tot$eFG. <- NULL
df.tot$PF <- NULL
df.tot$FPM <- NULL
df.tot[,"FG."]=df.tot[,"FG"]/df.tot[,"FGA"]
df.tot$T3P.=df.tot$T3P/df.tot$T3PA
df.tot$T2P.=df.tot$T2P/df.tot$T2PA
df.tot$eFG.=(df.tot$FG+0.5*df.tot$T3P)/df.tot$FGA
df.tot$FT.=df.tot$FT/df.tot$FTA
df.tot$FP=df.tot$AST*2+df.tot$ORB*1.5+df.tot$DRB+df.tot$BLK*2+df.tot$STL*2+df.tot$FT*1.5+
df.tot$T2P*2.5+df.tot$T3P*3.5-df.tot$FTA*0.5-df.tot$T2PA*0.5-df.tot$T3PA*0.5-
df.tot$TOV*2
df.tot$MPPG <- df.tot$MP/df.tot$G
df.tot$FPPG <- df.tot$FP/df.tot$G
df.tot$FPPM <- df.tot$FP/df.tot$MP
return(df.tot)
}
runApp('C:/Users/e050752/Desktop/BBall')
runApp('C:/Users/e050752/Desktop/BBall')
runApp('C:/Users/e050752/Desktop/BBall')
df2 <- readHTMLTable(getURL("https://www.basketball-reference.com/players/p/paulch01/gamelog/2017/#pgl_basic::none"))$pgl_basic
install.packages("rvest")
library(rvest)
aPaclist <- c("RCurl","dplyr","XML","xlsx")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
lapply(aPaclist,require,character.only=T)
df <- readHTMLTable(getURL("https://www.basketball-reference.com/players/g/griffbl01/gamelog/2017/#pgl_basic::none"))$pgl_basic
aPaclist <- c("xts","zoo","plyr","MTS","xlsx","gdata","forecast","ggplot2","lubridate")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
# library(xts)
# library(zoo)
# library(plyr)
# library(MTS)
# library(xlsx)
# library(gdata)
# library(forecast)
# library(ggplot2)
# library(lubridate)
# Read Google Data
# Select the folder where to read from
sFold = "H:/DATOS_BBVAResearch/FENIX_SC001628/Modelos/Turismo-Google/Flash"
vGuard <- 1
mData <- read.csv(paste(sFold,"/original.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding="latin1")
mData <- xts(mData[,-1], order.by=as.Date(mData$date))
mData0 <- read.csv(paste(sFold,"/datos_brutos/data-00000-of-00001.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding = "latin1")
mData0$CCAA <- gsub("Ã³","ó",mData0$CCAA)
mData0 <- xts(mData0[,-1], order.by=as.Date(mData0$date))
# Define name vectors
vCountry = c("AT", "CH", "DE","FR","IE","IT","UK","US","ES")
vCCAAabv <- c("ESP","AND","ARA","AST","BAL","CAN","CNT","CYL","CLM","CAT","VAL","EXT","GAL",
"MAD","MUR","NAV","PV","RIO")
vCCAA <- c("Spain","Andalusia","Aragon","Asturias","Balearic Islands","Canary Islands",
"Cantabria","Castille and León","Castile La Mancha","Catalonia","Valencian Community",
"Extremadura","Galicia","Community of Madrid","Region of Murcia","Navarre","Basque Country",
"La Rioja")
iC = length(vCountry)
# iP = length(vProd)
iCCAA <- length(vCCAA)
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData[mData$CCAA==vCCAA[m] &  mData$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData = do.call(merge, objList)    # merge all objects in list
# new data
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData0[mData0$CCAA==vCCAA[m] &  mData0$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var_new', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var_new*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData0 = do.call(merge, objList)    # merge all objects in list
# Delete variable which are not used
rm(list=
Filter(
Negate(is.na),                                  # filter entries corresponding to objects that don't meet function criteria
sapply(
ls(pattern="var*"),                             # only objects that start with "var"
function(x) if(is.matrix(get(x))) x else NA   # return names of matrix objects
)
)
)
mDf.tot <- mData
mDf.tot0 <- mData0
col <- which(!(colnames(mDf.tot) %in% colnames(mDf.tot0)))
colnames(mDf.tot)[col]
mDf.tot = mDf.tot["2007-07-01/2015-12-31"]
mDf.tot0 = mDf.tot0["2016-01-01/"]
mData_vf = rbind(mDf.tot, mDf.tot0)
#remove outliers
fun <- function(x){
quantiles <- quantile( x, c(.05, .97 ) )
x[ x < quantiles[1] ] <- quantiles[1]
x[ x > quantiles[2] ] <- quantiles[2]
x
}
mData_vf <- lapply(mData_vf,fun)
mData_vf <- as.data.frame(mData_vf)
mData_vf <- xts(mData_vf,order.by = as.Date(rownames(mData_vf)))
#create monthly and two week form raw data
mMonthly_raw = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week_raw = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week_raw = apply.monthly(mData_vf_two_week_raw, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales/Datos_brutos"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleWeekly_raw')
write.xlsx(mMonthly_raw, paste(sFold,Regionales,"/GoogleMonthly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_raw')
write.xlsx(mMonthly_two_week_raw,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks_raw')
}
# Indexing all series (equal 100 in the first week of data)
for (i in 1:ncol(mData_vf)){
iNonNA <- which(!is.na(mData_vf[,c(i)]))
iNonNAfst <- min(iNonNA) #encuentra el primer valor que no es NA y guarda su localizacióndim
dA = coredata(mData_vf[iNonNAfst,c(i)])
mData_vf[,c(i)] = drop(mData_vf[,c(i)])/dA*100 #divide todos entre ese valor *100
}
mMonthly = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week = apply.monthly(mData_vf_two_week, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg.xlsx",sep = ''), sheetName = 'GoogleWeekly')
write.xlsx(mMonthly, paste(sFold,Regionales,"/GoogleMonthly_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly')
write.xlsx(mMonthly_two_week,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks')
}
### NO MODIFICAR NADA DEL CÓDIGO ###
aPaclist <- c("jsonlite","lubridate","rstudioapi","xlsx","dplyr","xts")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
INEador <- function(cArch){
cPath <- sub("/[^/]*$","",getActiveDocumentContext()$path)
mDat <- read.xlsx(paste(cPath,cArch,sep="/"),sheetIndex = 1)
codigos <- paste(mDat[,1],mDat[,2],sep="")
nombres <- mDat[,3]
years <- mDat[,4]
for (i in 1:length(codigos)) {
cBase <- "http://servicios.ine.es/wstempus/js/ES/DATOS_SERIE"
cCod <- codigos[i]
cDat <- paste(years[i],"0101:",sep="")
cMed <- paste(cBase,cCod,sep="/")
enlace <- paste(cMed,cDat,sep="?page=1&date=")
json_data2 <- fromJSON(paste(readLines(enlace),collapse=""),simplifyDataFrame = T)
l <- json_data2[["Data"]]
l <- xts(l[,5],order.by=as.Date(parse_date_time(paste(l[,4],l[,3],sep="-"),"ym")))
print(paste(nombres[i]," descargada -> ",i," series listas",sep=""))
if (i==1) {
dfINE <- l
} else {
dfINE <- cbind(dfINE,l)
}
}
colnames(dfINE) <- nombres
return(dfINE)
}
#conseguir datos
dfINE <- INEador("Input_R.xlsx")
#grabar resultados en Excel
cPath <- sub("/[^/]*$","",getActiveDocumentContext()$path)
write.xlsx(dfINE,paste(cPath,"/Output_R.xlsx",sep=""),sheetName = "Hoja1",showNA=F)
### NO MODIFICAR NADA DEL CÓDIGO ###
aPaclist <- c("jsonlite","lubridate","rstudioapi","xlsx","dplyr","xts")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
INEador <- function(cArch){
cPath <- sub("/[^/]*$","",getActiveDocumentContext()$path)
mDat <- read.xlsx(paste(cPath,cArch,sep="/"),sheetIndex = 1)
codigos <- paste(mDat[,1],mDat[,2],sep="")
nombres <- mDat[,3]
years <- mDat[,4]
for (i in 1:length(codigos)) {
cBase <- "http://servicios.ine.es/wstempus/js/ES/DATOS_SERIE"
cCod <- codigos[i]
cDat <- paste(years[i],"0101:",sep="")
cMed <- paste(cBase,cCod,sep="/")
enlace <- paste(cMed,cDat,sep="?page=1&date=")
json_data2 <- fromJSON(paste(readLines(enlace),collapse=""),simplifyDataFrame = T)
l <- json_data2[["Data"]]
l <- xts(l[,5],order.by=as.Date(parse_date_time(paste(l[,4],l[,3],sep="-"),"ym")))
print(paste(nombres[i]," descargada -> ",i," series listas",sep=""))
if (i==1) {
dfINE <- l
} else {
dfINE <- cbind(dfINE,l)
}
}
colnames(dfINE) <- nombres
return(dfINE)
}
#conseguir datos
dfINE <- INEador("Input_R.xlsx")
#grabar resultados en Excel
cPath <- sub("/[^/]*$","",getActiveDocumentContext()$path)
write.xlsx(dfINE,paste(cPath,"/Output_R.xlsx",sep=""),sheetName = "Hoja1",showNA=F)
cPath <- sub("/[^/]*$","",getActiveDocumentContext()$path)
write.xlsx(dfINE,paste(cPath,"/Output_R.xlsx",sep=""),sheetName = "Hoja1",showNA=F)
shiny::runApp('C:/Users/e050752/Desktop/BBall')
aPaclist <- c("xts","zoo","plyr","MTS","xlsx","gdata","forecast","ggplot2","lubridate")
lapply(aPaclist,function(x) if (!require(x,character.only=T)) install.packages(x))
# library(xts)
# library(zoo)
# library(plyr)
# library(MTS)
# library(xlsx)
# library(gdata)
# library(forecast)
# library(ggplot2)
# library(lubridate)
# Read Google Data
# Select the folder where to read from
sFold = "H:/DATOS_BBVAResearch/FENIX_SC001628/Modelos/Turismo-Google/Flash"
vGuard <- 1
mData <- read.csv(paste(sFold,"/original.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding="latin1")
mData <- xts(mData[,-1], order.by=as.Date(mData$date))
mData0 <- read.csv(paste(sFold,"/datos_brutos/data-00000-of-00001.csv",sep = ''), header=T, dec=".", sep=",",fileEncoding = "latin1")
mData0$CCAA <- gsub("Ã³","ó",mData0$CCAA)
mData0 <- xts(mData0[,-1], order.by=as.Date(mData0$date))
# Define name vectors
vCountry = c("AT", "CH", "DE","FR","IE","IT","UK","US","ES")
vCCAAabv <- c("ESP","AND","ARA","AST","BAL","CAN","CNT","CYL","CLM","CAT","VAL","EXT","GAL",
"MAD","MUR","NAV","PV","RIO")
vCCAA <- c("Spain","Andalusia","Aragon","Asturias","Balearic Islands","Canary Islands",
"Cantabria","Castille and León","Castile La Mancha","Catalonia","Valencian Community",
"Extremadura","Galicia","Community of Madrid","Region of Murcia","Navarre","Basque Country",
"La Rioja")
iC = length(vCountry)
# iP = length(vProd)
iCCAA <- length(vCCAA)
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData[mData$CCAA==vCCAA[m] &  mData$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData = do.call(merge, objList)    # merge all objects in list
# new data
iH = 100
for(m in 1:iCCAA){
for (j in 1:iC) {
mAux <- mData0[mData0$CCAA==vCCAA[m] &  mData0$GEO == vCountry[j]] #filter by the selected prd and cons
mAux <- mAux[,c(5)]
colnames(mAux)[1] <- paste(vCCAAabv[m],vCountry[j], sep="_")
storage.mode(mAux) <- 'numeric'
if (length(mAux) != 0){
mAux = apply.weekly(mAux, function(x) apply(x, 2, sum))
assign(paste('var_new', iH, sep = ''), mAux)
iH = iH+1
}
}
}
objNames <- ls(pattern="var_new*")    # object names
objList <- lapply(objNames, get)  # list of objects
names(objList) <- objNames        # assign names to list
mData0 = do.call(merge, objList)    # merge all objects in list
# Delete variable which are not used
rm(list=
Filter(
Negate(is.na),                                  # filter entries corresponding to objects that don't meet function criteria
sapply(
ls(pattern="var*"),                             # only objects that start with "var"
function(x) if(is.matrix(get(x))) x else NA   # return names of matrix objects
)
)
)
mDf.tot <- mData
mDf.tot0 <- mData0
col <- which(!(colnames(mDf.tot) %in% colnames(mDf.tot0)))
colnames(mDf.tot)[col]
mDf.tot = mDf.tot["2007-07-01/2015-12-31"]
mDf.tot0 = mDf.tot0["2016-01-01/"]
mData_vf = rbind(mDf.tot, mDf.tot0)
#remove outliers
fun <- function(x){
quantiles <- quantile( x, c(.05, .97 ) )
x[ x < quantiles[1] ] <- quantiles[1]
x[ x > quantiles[2] ] <- quantiles[2]
x
}
mData_vf <- lapply(mData_vf,fun)
mData_vf <- as.data.frame(mData_vf)
mData_vf <- xts(mData_vf,order.by = as.Date(rownames(mData_vf)))
#create monthly and two week form raw data
mMonthly_raw = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week_raw = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week_raw = apply.monthly(mData_vf_two_week_raw, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales/Datos_brutos"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleWeekly_raw')
write.xlsx(mMonthly_raw, paste(sFold,Regionales,"/GoogleMonthly_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_raw')
write.xlsx(mMonthly_two_week_raw,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg_raw.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks_raw')
}
# Indexing all series (equal 100 in the first week of data)
for (i in 1:ncol(mData_vf)){
iNonNA <- which(!is.na(mData_vf[,c(i)]))
iNonNAfst <- min(iNonNA) #encuentra el primer valor que no es NA y guarda su localizacióndim
dA = coredata(mData_vf[iNonNAfst,c(i)])
mData_vf[,c(i)] = drop(mData_vf[,c(i)])/dA*100 #divide todos entre ese valor *100
}
mMonthly = apply.monthly(mData_vf, function(x) apply(x, 2, mean, na.rm=TRUE))
mData_vf_two_week = do.call(rbind, lapply(split(mData_vf, "months"), function(x) x[c(1,2)]))
mMonthly_two_week = apply.monthly(mData_vf_two_week, function(x) apply(x, 2, mean, na.rm=TRUE))
if (vGuard==1) {
Regionales="/Regionales"
write.xlsx(mData_vf, paste(sFold,Regionales,"/GoogleWeekly_reg.xlsx",sep = ''), sheetName = 'GoogleWeekly')
write.xlsx(mMonthly, paste(sFold,Regionales,"/GoogleMonthly_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly')
write.xlsx(mMonthly_two_week,paste(sFold,Regionales,"/GoogleMonthly_two_weeks_reg.xlsx",sep = ''), sheetName = 'GoogleMonthly_two_weeks')
}
tail(mData0,1)
runApp('C:/Users/e050752/Desktop/BBall')
runApp('C:/Users/e050752/Desktop/BBall')
runGitHub("Mapas_BBVA_municipios","IArchondo")
runApp('C:/Users/e050752/Desktop/BBall')
